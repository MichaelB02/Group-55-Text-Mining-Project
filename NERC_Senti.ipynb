{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07efe9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "NER_path = 'multinerd_en.tsv'\n",
    "NER_test = 'NER-final-test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec20d57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#NER\n",
    "\n",
    "NER_dataset = pandas.read_csv(NER_path,sep='\\t',error_bad_lines=False,encoding='utf8',header=None,quoting=3)\n",
    "\n",
    "df_test = pandas.read_csv(NER_test,sep='\\t',error_bad_lines=False,encoding='utf8',quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91233d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token id</th>\n",
       "      <th>token</th>\n",
       "      <th>BIO NER tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>11</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>12</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>13</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>14</td>\n",
       "      <td>Die</td>\n",
       "      <td>B-MEDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>15</td>\n",
       "      <td>Fledermaus</td>\n",
       "      <td>I-MEDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>16</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>17</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>18</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>19</td>\n",
       "      <td>Ravel</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>20</td>\n",
       "      <td>’s</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token id       token BIO NER tag\n",
       "850        11           \"           O\n",
       "851        12           ,           O\n",
       "852        13           \"           O\n",
       "853        14         Die     B-MEDIA\n",
       "854        15  Fledermaus     I-MEDIA\n",
       "855        16           \"           O\n",
       "856        17           ,           O\n",
       "857        18         and           O\n",
       "858        19       Ravel       B-PER\n",
       "859        20          ’s           O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = NER_dataset\n",
    "df = df[[0,1,2]]\n",
    "df.columns= ['token id','token','BIO NER tag']\n",
    "df_train = df[:100000]\n",
    "df[850:860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c413118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features=[]\n",
    "training_gold_labels=[]\n",
    "\n",
    "for ind in df_train.index:\n",
    "    a_dict = {\n",
    "        'words':df_train['token'][ind]\n",
    "    }\n",
    "    training_features.append(a_dict)\n",
    "    training_gold_labels.append(df_train['BIO NER tag'][ind])\n",
    "    \n",
    "test_features=[]\n",
    "test_gold_labels=[]\n",
    "\n",
    "for ind in df_test.index:\n",
    "    a_dict = {\n",
    "        'words':df_test['token'][ind]\n",
    "    }\n",
    "    test_features.append(a_dict)\n",
    "    test_gold_labels.append(df_test['BIO NER tag'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f536ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()\n",
    "an_array = training_features + test_features\n",
    "\n",
    "the_array = vec.fit_transform(an_array)\n",
    "\n",
    "new_training = the_array[:100000]\n",
    "new_test = the_array[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a646b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63d6b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'O': 87144,\n",
       "          'B-PER': 2525,\n",
       "          'I-PER': 2626,\n",
       "          'B-LOC': 1565,\n",
       "          'B-MEDIA': 308,\n",
       "          'I-MEDIA': 519,\n",
       "          'B-TIME': 84,\n",
       "          'B-EVE': 109,\n",
       "          'I-EVE': 174,\n",
       "          'I-TIME': 68,\n",
       "          'I-LOC': 762,\n",
       "          'B-ORG': 838,\n",
       "          'I-ORG': 1146,\n",
       "          'B-PLANT': 213,\n",
       "          'B-ANIM': 339,\n",
       "          'I-ANIM': 212,\n",
       "          'I-PLANT': 78,\n",
       "          'B-FOOD': 296,\n",
       "          'B-DIS': 427,\n",
       "          'I-DIS': 316,\n",
       "          'B-CEL': 51,\n",
       "          'B-SUPER': 12,\n",
       "          'I-SUPER': 3,\n",
       "          'I-FOOD': 112,\n",
       "          'B-VEHI': 6,\n",
       "          'I-VEHI': 4,\n",
       "          'B-INST': 8,\n",
       "          'I-INST': 8,\n",
       "          'I-CEL': 33,\n",
       "          'B-PHY': 2,\n",
       "          'I-PHY': 3,\n",
       "          'B-BIO': 7,\n",
       "          'I-BIO': 2}),\n",
       " Counter({'O': 183,\n",
       "          'B-ORG': 4,\n",
       "          'I-ORG': 3,\n",
       "          'B-LOC': 4,\n",
       "          'B-MISC': 3,\n",
       "          'B-PER': 6,\n",
       "          'I-PER': 8,\n",
       "          'I-MISC': 1,\n",
       "          'I-LOC': 2}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "Counter(training_gold_labels),Counter(test_gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9e56c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-ANIM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PER</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MEDIA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PHY</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.989071</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.897196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.389670</td>\n",
       "      <td>0.304645</td>\n",
       "      <td>0.319466</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.896958</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.885472</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "B-ANIM         0.000000  0.000000  0.000000    0.000000\n",
       "B-LOC          0.400000  0.500000  0.444444    4.000000\n",
       "B-MISC         0.000000  0.000000  0.000000    3.000000\n",
       "B-ORG          0.333333  0.250000  0.285714    4.000000\n",
       "B-PER          1.000000  0.500000  0.666667    6.000000\n",
       "I-LOC          0.500000  0.500000  0.500000    2.000000\n",
       "I-MEDIA        0.000000  0.000000  0.000000    0.000000\n",
       "I-MISC         0.000000  0.000000  0.000000    1.000000\n",
       "I-ORG          0.500000  0.666667  0.571429    3.000000\n",
       "I-PER          1.000000  0.250000  0.400000    8.000000\n",
       "I-PHY          0.000000  0.000000  0.000000    0.000000\n",
       "O              0.942708  0.989071  0.965333  183.000000\n",
       "accuracy       0.897196  0.897196  0.897196    0.897196\n",
       "macro avg      0.389670  0.304645  0.319466  214.000000\n",
       "weighted avg   0.896958  0.897196  0.885472  214.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf.fit(new_training, training_gold_labels) \n",
    "predicted_labels = lin_clf.predict(new_test)\n",
    "\n",
    "NERC_report = classification_report(test_gold_labels, predicted_labels,output_dict=True)\n",
    "\n",
    "NERC_cr_df = pandas.DataFrame(NERC_report).transpose()\n",
    "NERC_cr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c244039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a53a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment\n",
    "# senti_path_finance = 'senti-data.csv'\n",
    "# senti_path_movie = 'IMDB_Dataset.csv'\n",
    "senti_test = 'sentiment-topic-final-test.tsv'\n",
    "# senti_twitter ='Twitter_Data.csv'\n",
    "senti_reddit ='Reddit_Data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3150fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# df_senti_movie = pandas.read_csv(senti_path_movie,encoding='utf8')\n",
    "# df_senti_finance = pandas.read_csv(senti_path_finance,encoding='latin-1',header=None)\n",
    "df_senti_test = pandas.read_csv(senti_test,sep='\\t',error_bad_lines=False,encoding='utf8',quoting=3)\n",
    "\n",
    "df_senti_reddit = pandas.read_csv(senti_reddit,encoding='utf8')\n",
    "# df_senti_twitter = pandas.read_csv(senti_twitter,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb305182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti_reddit.rename(columns={'clean_comment':'Sentence','category':'Sentiment'},inplace = True)\n",
    "df_senti_reddit['Sentiment']=df_senti_reddit['Sentiment'].replace({-1:'negative',0:'neutral',1:'positive'})\n",
    "df_senti_reddit = df_senti_reddit.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34973696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    15830\n",
       "neutral     13042\n",
       "negative     8277\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_senti_reddit['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10610535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It took eight years for Warner Brothers to rec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All the New York University students love this...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This Italian place is really trendy but they h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In conclusion, my review of this book would be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The story of this movie is focused on Carl Bra...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chris O'Donnell stated that while filming for ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>My husband and I moved to Amsterdam 6 years ag...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dame Maggie Smith performed her role excellent...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The new movie by Mr. Kruno was shot in New Yor...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I always have loved English novels, but I just...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  It took eight years for Warner Brothers to rec...  negative\n",
       "1  All the New York University students love this...  positive\n",
       "2  This Italian place is really trendy but they h...  negative\n",
       "3  In conclusion, my review of this book would be...  positive\n",
       "4  The story of this movie is focused on Carl Bra...   neutral\n",
       "5  Chris O'Donnell stated that while filming for ...   neutral\n",
       "6  My husband and I moved to Amsterdam 6 years ag...  positive\n",
       "7  Dame Maggie Smith performed her role excellent...  positive\n",
       "8  The new movie by Mr. Kruno was shot in New Yor...   neutral\n",
       "9  I always have loved English novels, but I just...  negative"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_senti_test.rename(columns={'text':'Sentence','sentiment':'Sentiment'},inplace=True)\n",
    "# df_senti_test\n",
    "df_senti_test = df_senti_test[['Sentence','Sentiment']]\n",
    "df_senti_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6966f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    15834\n",
       "neutral     13045\n",
       "negative     8280\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_senti_movie = df_senti_movie.sample(5000)\n",
    "# df_senti_movie = df_senti_movie['Sentence'].str.replace(\"^\\\\<br>$\",\"\")\n",
    "df_senti = pandas.concat([df_senti_reddit, df_senti_test])\n",
    "# df_senti = pandas.concat([df_senti_movie, df_senti_test])\n",
    "df_senti['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "231e8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                             tokenizer=nltk.word_tokenize, # we use the nltk tokenizer\n",
    "                             stop_words=stopwords.words('english'))\n",
    "\n",
    "# vectorizer = TfidfVectorizer (min_df=5, \n",
    "#                               tokenizer = nltk.word_tokenize,\n",
    "#                               stop_words=stopwords.words('english'))\n",
    "combined_data = df_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06ce36df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37159, 25602)\n"
     ]
    }
   ],
   "source": [
    "training_data_senti = df_senti[['Sentence','Sentiment']]\n",
    "test_data_senti = df_senti_test[['Sentence','Sentiment']]\n",
    "# print(len(combined_data))\n",
    "# break\n",
    "new_combined_sentence = vectorizer.fit_transform(combined_data.Sentence).toarray()\n",
    "print(new_combined_sentence.shape)\n",
    "new_training_senti = new_combined_sentence[:37149]\n",
    "new_test_senti = new_combined_sentence[37149:]\n",
    "y_new_training = combined_data.Sentiment[:37149]\n",
    "y_new_test = combined_data.Sentiment[37149:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80307a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 25602)\n"
     ]
    }
   ],
   "source": [
    "print(new_test_senti.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "151d3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(new_training_senti,y_new_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c6a73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(new_test_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12f9f0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "negative       0.000000  0.000000      0.00      3.0\n",
       "neutral        0.500000  0.333333      0.40      3.0\n",
       "positive       0.375000  0.750000      0.50      4.0\n",
       "accuracy       0.400000  0.400000      0.40      0.4\n",
       "macro avg      0.291667  0.361111      0.30     10.0\n",
       "weighted avg   0.300000  0.400000      0.32     10.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTI_report = classification_report(y_new_test,y_pred,output_dict=True)\n",
    "\n",
    "SENTI_cr_df = pandas.DataFrame(SENTI_report).transpose()\n",
    "SENTI_cr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbd10fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words in negative documents\n",
      "negative 154.21486876002615 fuck\n",
      "negative 143.67658214449716 bjp\n",
      "negative 133.73004863759246 people\n",
      "negative 130.7966415692015 modi\n",
      "negative 124.86366680580251 shit\n",
      "negative 123.90423875675283 like\n",
      "negative 118.41284544317223 india\n",
      "negative 104.93082250961409 fucking\n",
      "negative 91.6900416140093 one\n",
      "negative 86.29371424730641 bad\n",
      "-----------------------------------------\n",
      "Important words in neutral documents\n",
      "neutral 176.93981752532682 modi\n",
      "neutral 130.1582944469837 bjp\n",
      "neutral 119.03731780256194 india\n",
      "neutral 112.45565503090161 like\n",
      "neutral 111.85639526339759 hai\n",
      "neutral 78.71411704028769 one\n",
      "neutral 72.72255398375265 get\n",
      "neutral 66.96004062040977 people\n",
      "neutral 63.9677560704131 congress\n",
      "neutral 61.790049718723964 time\n",
      "-----------------------------------------\n",
      "Important words in positive documents\n",
      "positive 325.53183184110674 good\n",
      "positive 261.55865904353 people\n",
      "positive 260.85464240083763 india\n",
      "positive 250.45549344130848 bjp\n",
      "positive 248.67965744498233 like\n",
      "positive 247.89308178288127 modi\n",
      "positive 206.54462874200453 one\n",
      "positive 192.46554785102168 would\n",
      "positive 180.16425907222654 right\n",
      "positive 163.30804061687994 much\n"
     ]
    }
   ],
   "source": [
    "def important_features_per_class(vectorizer,classifier,n=10): #n is the number of top features\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    topn_class3 = sorted(zip(classifier.feature_count_[2], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words in negative documents\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in neutral documents\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in positive documents\")\n",
    "    for coef, feat in topn_class3:\n",
    "        print(class_labels[2], coef, feat) \n",
    "\n",
    "# example of how to call from notebook:\n",
    "important_features_per_class(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbc673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
